{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from data_classes import *\n",
    "from models import SequentialNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\n",
    "    SAMPLING_METHOD=SamplingMethod.QMC,\n",
    "    SCENARIO=Scenario.SUM_SINES\n",
    ")\n",
    "\n",
    "scenario_settings = ScenarioSettings(experiment.SCENARIO)\n",
    "\n",
    "input_data = InputData(scenario_settings.DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [6,12,24]\n",
    "depths = [4,8,16]\n",
    "learning_rates = [0.01,0.001]\n",
    "lambdas = [1.0e-04,1.0e-05,1.0e-06,1e-07]\n",
    "training_set_sizes = scenario_settings.TRINING_SET_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_settings = []\n",
    "\n",
    "for width in widths:\n",
    "    for depth in depths:\n",
    "        for learning_rate in learning_rates:\n",
    "            for lambda_ in lambdas:\n",
    "                for training_set_size in training_set_sizes:\n",
    "                    nn_arch = NeuralNetworkArchitecture(\n",
    "                        INPUT_DIM=scenario_settings.INPUT_DIM,\n",
    "                        OUTPUT_DIM=scenario_settings.OUTPUT_DIM,\n",
    "                        NUM_HIDDEN_LAYERS=width,\n",
    "                        DEPTH=depth,\n",
    "                        ACTIVATION_FUNCTION=torch.nn.Sigmoid\n",
    "                    )\n",
    "                    training_config = AdamTrainingConfig(\n",
    "                        OPTIMIZER=OptimizationMethod.ADAM,\n",
    "                        LEARNING_RATE=learning_rate,\n",
    "                        REG_PARAM=lambda_,\n",
    "                        NUM_EPOCHS=1000,\n",
    "                        # WEIGHT_DECAY=0.0\n",
    "                    )\n",
    "\n",
    "                    training_settings.append(TrainingSetup(\n",
    "                        nn_architecture=nn_arch,\n",
    "                        training_config=training_config,\n",
    "                        training_set_size=training_set_size\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janikhrubant/Developer/Deep_NN_QMC/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.45229780673980713\n",
      "Generalization error: 0.48372945189476013\n",
      "Training complete after 1000 epochs.\n",
      "Optimizer: OptimizationMethod.ADAM\n",
      "Learning rate: 0.01\n",
      "Regularization parameter: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janikhrubant/Developer/Deep_NN_QMC/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:128: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/Users/janikhrubant/Developer/Deep_NN_QMC/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:128: UserWarning: Using a target size (torch.Size([8192])) that is different to the input size (torch.Size([8192, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.45229780673980713, 0.48372945189476013)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = training_settings[0]\n",
    "nn = SequentialNeuralNetwork(\n",
    "    net_arch=ts.nn_architecture\n",
    ")\n",
    "training_data = input_data.get_training_and_test_data(\n",
    "    sampling_method=experiment.SAMPLING_METHOD,\n",
    "    training_set_size=ts.training_set_size\n",
    ")\n",
    "nn.train(settings=ts.training_config, data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janikhrubant/Developer/Deep_NN_QMC/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.4523574113845825\n",
      "Generalization error: 0.48377007246017456\n",
      "Training complete after 1000 epochs.\n",
      "Optimizer: OptimizationMethod.ADAM\n",
      "Learning rate: 0.01\n",
      "Regularization parameter: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janikhrubant/Developer/Deep_NN_QMC/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:128: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/Users/janikhrubant/Developer/Deep_NN_QMC/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:128: UserWarning: Using a target size (torch.Size([8192])) that is different to the input size (torch.Size([8192, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "train_error_results = []\n",
    "test_error_results = []\n",
    "for ts in training_settings:\n",
    "    ts = training_settings[0]\n",
    "    nn = SequentialNeuralNetwork(\n",
    "        net_arch=ts.nn_architecture\n",
    "    )\n",
    "    training_data = input_data.get_training_and_test_data(\n",
    "        sampling_method=experiment.SAMPLING_METHOD,\n",
    "        training_set_size=ts.training_set_size\n",
    "    )\n",
    "    nn.train(settings=ts.training_config, data=training_data)\n",
    "\n",
    "    train_error_results.append(nn.train_error)\n",
    "    test_error_results.append(nn.test_error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
